{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexKressner/Business_Intelligence/blob/main/openai_api_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installation\n",
        "! pip install -q --upgrade cohere typing-extensions==4.5.0 openai tiktoken python-dotenv"
      ],
      "metadata": {
        "id": "eJW63IPK7iCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l36BZjQv7geT"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import tiktoken\n",
        "import math\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API Keys\n",
        "Damit Sie die OpenAI API nutzen können, müssen Sie einen API Key erstellen. Mit diesem authentifizieren Sie sich, wenn Sie Anfragen an den Service stellen. Wir werden Ihren **geheimen** API Key in einem sogenannten `.env`-file speichern. Aus diesem wird der Key als Umgebungsvariable geladen. Einen API Key können Sie [hier](https://platform.openai.com/api-keys) erstellen. Das `.env`-file wird gelöscht, sobald die Laufzeitumgebung in Colab von Ihnen geöscht wird."
      ],
      "metadata": {
        "id": "lw9CZ2Bn8H8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -a"
      ],
      "metadata": {
        "id": "NwLR3bnf9dV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lädt die Umgebungsvariablen aus der .env-Datei\n",
        "load_dotenv()\n",
        "\n",
        "# Zugriff auf die Umgebungsvariablen\n",
        "secret_key = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "fQQNI3utBaTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fT5xP0X7geV"
      },
      "source": [
        "# Einstieg\n",
        "Eine ausführliche Dokumentation zur OpenAI Entwickler-Plattform finden Sie unter diesem [Link](https://platform.openai.com/docs/overview). Die genaue Spezifikation der API, die wir verwenden werden, können Sie unter folgendem [Link](https://platform.openai.com/docs/api-reference) nachschlagen.\n",
        "\n",
        "Um Anfragen über die OpenAI API zu senden, müssen Sie zunächst ein Client-Objekt erstellen (`client = OpenAI()`). Den API Key übergeben wir als Argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9Ht2EfJ7geX"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=secret_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_2J2_nh7geX"
      },
      "source": [
        "Bei Verwendung der Chat-API unterscheidet man zwischen drei Rollen: **System**, **Assistent** und **Nutzer**.\n",
        "\n",
        "Beim **Assistenten** handelt es sich um das eigentliche Chat-Modell wie z.B. `gpt-3.5` oder `gpt-4`. Dieses tritt im Rahmen eines Chats (Konversation) in Interaktion mit dem **Nutzer**. Der Nutzer sendet einen Prompt an den Assistenten und dieser antwortet darauf. Das grundlegende Verhalten des Assistenten wird über die Beschreibung des **System**s gestaltet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26UjssQm7geY"
      },
      "outputs": [],
      "source": [
        "default_system_message = \"Du bist ein freundlicher und hilfsbereiter Assistent, der Kunden bei Fragen hilft\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm4Tt9Sr7geY"
      },
      "outputs": [],
      "source": [
        "# Hilfsfunktion zur Interaktion mit der Chat-API\n",
        "def get_completion(prompt, system_message=default_system_message, model=\"gpt-3.5-turbo\"):\n",
        "    system_message = [{\"role\": \"system\", \"content\": system_message}] # Wie soll sich das System grundlegend verhalten\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}] # Prompt des Nutzers\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=system_message+ messages,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xqxjp297gey"
      },
      "outputs": [],
      "source": [
        "prompt = \"Ich habe ein Problem mit meinem Smartphone und benötige Hilfe!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEKJ6X6N7gez"
      },
      "outputs": [],
      "source": [
        "get_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJrk6DfW7gez"
      },
      "outputs": [],
      "source": [
        "system_message = \"Du bist ein eher mürrischer Assistent. Du sprichst möglich wenig Wörter\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vDbmO-Z7ge0"
      },
      "outputs": [],
      "source": [
        "get_completion(prompt, system_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn7ceEcF7ge0"
      },
      "source": [
        "# Der Chat-Endpunkt im Detail\n",
        "Der Chat-Endpunkt ist detailliert unter dem folgendem [Link](https://platform.openai.com/docs/api-reference/chat?lang=python) dokumentiert. Wir betrachten zunächst das \"chat completion object\", d.h. die Antwort des Chat-Endpunkts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJasK5yq7ge0"
      },
      "outputs": [],
      "source": [
        "prompt = \"Hallo, ich bin Alex\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmXVDGCX7ge1"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    )\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvL1Pesq7ge1"
      },
      "outputs": [],
      "source": [
        "# Attribute des ChatCompletion Objekts\n",
        "response.choices[0].message.content, response.usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y64B4jdZ7ge1"
      },
      "source": [
        "# Tokens\n",
        "\"Token\" im Zusammenhang mit Large Language Models (LLMs) wie GPT-3 oder GPT-4 beziehen sich auf die grundlegenden Einheiten der Datenverarbeitung, die das Modell verwendet, um Text zu interpretieren und zu generieren. Ein Token kann ein Wort, ein Teil eines Wortes oder sogar ein einzelnes Zeichen sein. Ein Text wird in die definierten Tokens zerlegt. Anschließend wir jeder Token in einen numerischen Wert umgewandelt. Diese Werte sind Indizes, die den entsprechenden Token im Vokabular des Modells repräsentieren.\n",
        "\n",
        "Wir verwenden hier den Byte Pair Encoding (BPE) Tokenizer [tiktoken](https://github.com/openai/tiktoken), der speziell für die Nutzung mit OpenAI Modellen entwickelt wurde. Ein BPE Tokenizer teilt Wörter in häufig vorkommende Buchstabenpaare oder Gruppen auf. Es ist besonders nützlich, um mit einem begrenzten Vokabular eine Vielzahl von Wörtern und Wortformen abzudecken.\n",
        "\n",
        "Ein ausführliches Beispiel zur Verwendung von tiktoken finden Sie [hier](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhyhEftE7ge1"
      },
      "outputs": [],
      "source": [
        "prompt = \"Hallo, meine Name ist Alexander Kressner\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUO9Q-2s7ge2"
      },
      "outputs": [],
      "source": [
        "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hTrKQBY7ge2"
      },
      "outputs": [],
      "source": [
        "tokens = encoding.encode(prompt)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hy20SQ97ge2"
      },
      "outputs": [],
      "source": [
        "encoding.decode(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqxYNEbG7ge3"
      },
      "outputs": [],
      "source": [
        "[encoding.decode_single_token_bytes(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aBrwigU7ge3"
      },
      "outputs": [],
      "source": [
        "name = \"Alexander\"\n",
        "prompt = f\"Bitte buchstabiere meinen Nachnamen '{name}' rückwärts\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXojm_He7ge3"
      },
      "outputs": [],
      "source": [
        "encoding.encode(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5jdhsdE7ge3"
      },
      "outputs": [],
      "source": [
        "get_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fcvm-DK-7ge3"
      },
      "outputs": [],
      "source": [
        "name = \"A-l-e-x-a-n-d-e-r\"\n",
        "prompt = f\"Bitte buchstabiere meinen Nachnamen '{name}' rückwärts\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGrnk8-i7ge4"
      },
      "outputs": [],
      "source": [
        "tokens = encoding.encode(name)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk9TBGQf7ge4"
      },
      "outputs": [],
      "source": [
        "[encoding.decode_single_token_bytes(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSYkjRNi7ge4"
      },
      "outputs": [],
      "source": [
        "get_completion(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWXBq3p27ge4"
      },
      "source": [
        "## Argumente für den Chat-Endpunkt\n",
        "Wenn Sie Anfragen an den [Chat-Endpunkt](https://platform.openai.com/docs/api-reference/chat) stellen, können Sie verschiedene Argumente übergeben. Die wichtigsten wollen wir einmal näher betrachten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwhQY1RP7ge4"
      },
      "outputs": [],
      "source": [
        "prompt = \"Hallo, meine Name ist Alex\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT0izKSm7ge4"
      },
      "outputs": [],
      "source": [
        "default_keyword_args = {\n",
        "    \"model\":\"gpt-3.5-turbo\",\n",
        "    \"messages\":[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOx-U26z7ge5"
      },
      "source": [
        "### `logprobs`\n",
        "Wenn diese Option aktiviert ist (also \"true\"), dann gibt das System die logarithmierten Wahrscheinlichkeiten jedes einzelnen Ausgabetokens, die im Inhalt der Nachricht enthalten sind, zurück."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARNtLQwV7ge5"
      },
      "outputs": [],
      "source": [
        "keyword_args = default_keyword_args | {\"logprobs\":True}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSQxplNI7ge5"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(**keyword_args)\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD3csGf77ge5"
      },
      "outputs": [],
      "source": [
        "response.choices[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_hBJQIk7ge5"
      },
      "outputs": [],
      "source": [
        "math.exp(response.choices[0].logprobs.content[0].logprob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxQyQOca7ge5"
      },
      "outputs": [],
      "source": [
        "{Token.token:math.exp(Token.logprob) for Token in response.choices[0].logprobs.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPOejwqB7ge5"
      },
      "source": [
        "### `top_logprobs`\n",
        "Beschreibt einen Parameter, der einen ganzzahligen Wert zwischen 0 und 5 annimmt. Dieser Wert spezifiziert die Anzahl der wahrscheinlichsten Tokens, die an jeder Token-Position zurückgegeben werden sollen, wobei jedem Token eine zugehörige logarithmierte Wahrscheinlichkeit beigefügt ist. Der Parameter `logprobs` muss auf `true` gesetzt werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdDJsM817ge5"
      },
      "outputs": [],
      "source": [
        "keyword_args = default_keyword_args | {\"logprobs\":True, \"top_logprobs\":3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tYb4kpj7ge5"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(**keyword_args)\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txaOATsC7ge6"
      },
      "outputs": [],
      "source": [
        "response.choices[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9VTqrFn7ge6"
      },
      "outputs": [],
      "source": [
        "toplogs = {TopLog.token:math.exp(TopLog.logprob) for TopLog in response.choices[0].logprobs.content[0].top_logprobs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru_Y8QLf7ge6"
      },
      "outputs": [],
      "source": [
        "toplogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYMCT-dV7ge6"
      },
      "source": [
        "### `logit_bias`\n",
        "Ändere die Wahrscheinlichkeit des Erscheinens bestimmter Tokens in der Vervollständigung. Die Bias-Werte reichen von -100 bis 100. Negative/Positive Werte verringern/erhöhen die Wahrscheinlichkeit der Auswahl. Werte von -100 oder 100 sollten zu einem Verbot des relevanten Tokens führen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldR6CCV47ge6"
      },
      "outputs": [],
      "source": [
        "token = encoding.encode(\"Hallo\")\n",
        "token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYmYPuIb7ge6"
      },
      "outputs": [],
      "source": [
        "keyword_args = default_keyword_args | {\"logit_bias\":{token[0]:-100}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXRaQQai7ge7"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(**keyword_args)\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWsUjGIn7ge7"
      },
      "source": [
        "### `max_tokens`\n",
        "Die maximale Anzahl an Tokens, die in der Chat-Vervollständigung generiert werden können. Die Gesamtlänge der Eingabetokens und der generierten Tokens wird durch die Kontextlänge des Modells begrenzt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKIs8gRW7ge7"
      },
      "outputs": [],
      "source": [
        "print(f\"\"\"\n",
        "      Anzahl input token gesamt = {response.usage.prompt_tokens} \\n\n",
        "      Anzahl output token gesamt = {response.usage.completion_tokens} \\n\n",
        "      Anzahl token gesamt = {response.usage.total_tokens}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faSmwk8G7ge7"
      },
      "outputs": [],
      "source": [
        "keyword_args = default_keyword_args | {\"max_tokens\":10}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poObOR6v7ge7"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(**keyword_args)\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbZVy6OG7ge7"
      },
      "source": [
        "### `response_format`\n",
        "Spezifiziert das Ausgabeformat des Modells (JSON oder Text)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe7oAOMb7ge7"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EDIMNer7ge7"
      },
      "outputs": [],
      "source": [
        "keyword_args = default_keyword_args | {\n",
        "    \"response_format\":{\"type\": \"json_object\"},\n",
        "    \"model\":\"gpt-3.5-turbo-1106\",\n",
        "    \"messages\":[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant and answer in json format.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "}\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_Yi81lc7ge7"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(**keyword_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwT74c6O7ge7"
      },
      "outputs": [],
      "source": [
        "response_dict = json.loads(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMsTFnwq7ge8"
      },
      "outputs": [],
      "source": [
        "response_dict[\"message\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ6uXhbP7ge8"
      },
      "source": [
        "### `temperatur`\n",
        "Der Parameter kann Werte zwischen 0 und 2 annehmen. Höhere Werte wie 0,8 machen die Ausgabe zufälliger, während niedrigere Werte wie 0,2 sie fokussierter und deterministischer machen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of-UyXgA7ge8"
      },
      "outputs": [],
      "source": [
        "prompt = \"Bitte schreib mir ein Gedicht, dass Studierende motiviert der Vorlesung zur künstlichen Intelligenz aufmerksam zu folgen und aktiv teilzunehmen! Bitte schreibe maximal 30 Wörter!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_uUBVZR7ge8"
      },
      "outputs": [],
      "source": [
        "default_keyword_args = {\n",
        "    \"model\":\"gpt-3.5-turbo\",\n",
        "    \"messages\":[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SACbBMhx7ge8"
      },
      "outputs": [],
      "source": [
        "keyword_args = default_keyword_args | {\"temperature\":0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCLS0eJb7ge8"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(**keyword_args)\n",
        "pprint.pprint(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvInXzjG7ge8"
      },
      "outputs": [],
      "source": [
        "keyword_args = default_keyword_args | {\"temperature\":1.5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26g2kgQg7ge8"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(**keyword_args)\n",
        "pprint.pprint(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPOzzEVl7ge8"
      },
      "source": [
        "# Beispiel: Web-Scapping + Chat API\n",
        "Wir wollen in nachfolgenden Beispiel Daten von einer Website laden (scrappen) und mittels Chat-API analysieren. Wir nutzen dafür die Bibliothek `requests` und `BeautifulSoup`. Das Python-Paket `requests` ist eine benutzerfreundliche Bibliothek, die das Senden von HTTP-Anfragen ermöglicht und eine einfache Verwendung für den Zugriff auf Web-Ressourcen bietet. `BeautifulSoup` ist eine Python-Bibliothek, die zur Analyse und Extraktion von Daten aus HTML- und XML-Dateien dient und dabei eine einfache Schnittstelle für das Parsen und Navigieren im Dokumentenbaum bietet."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q beautifulsoup4"
      ],
      "metadata": {
        "id": "ARBMQRGOCr7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V57dU9VA7ge8"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsagXGPr7ge9"
      },
      "outputs": [],
      "source": [
        "def get_website_text(url: str):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Überprüfen, ob die Anfrage erfolgreich war\n",
        "    if response.status_code == 200:\n",
        "        # Parsen des HTML-Inhalts der Seite\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extrahieren sämtlichen Textes der Webseite\n",
        "        text = soup.get_text(separator=' ', strip=True)\n",
        "        return text\n",
        "    else:\n",
        "        # Zurückgeben einer Fehlermeldung mit dem HTTP-Statuscode\n",
        "        return f\"Fehler beim Abrufen der Webseite: HTTP-Statuscode {response.status_code}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKhj6l2c7ge9"
      },
      "outputs": [],
      "source": [
        "text = get_website_text(\"https://www.lappcareer.com/stellenangebote.html?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha-flqMK7ge9"
      },
      "outputs": [],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMm0YprH7ge9"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, system_message=default_system_message, model=\"gpt-3.5-turbo\"):\n",
        "    system_message = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=system_message+ messages,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdhMV9dQ7ge9"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Du erhälst nachfolgend einen Text, der die ausgeschriebenen Stellen eines Unternehmens auf seiner Website wiedergibt!\n",
        "Gibt es Stellenausschreibungen für ein Duales Studium? Falls ja, bitte nenne die Ausschreibungen!\n",
        "Der relevante Text folgt nach dem Doppelpunkt: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfmWL_-j7ge9"
      },
      "outputs": [],
      "source": [
        "print(get_completion(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "npaAaWp1DMzm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "openai-api-zmtW_ZPs-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}